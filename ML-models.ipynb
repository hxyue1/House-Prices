{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will assess a variety of ML algorithms in their performance in predicting house prices. We'll be considering lasso and ridge regression, random forests, xgboost and maybe later light gbm. All models will be tuned via Bayesian Optimisation in order to minimise the average 5-fold cross validation score. Note that here specifically we are predicting log house prices and using the RMSE metric so our model evaluation will need to be tailored to that.\n",
    "\n",
    "First we'll import the data and clean it so that it can be used in a ML friendly format. We'll use a combination of random shuffling and forward filling to get rid of the NAs and convert the strings into dummy variables. We will not be exploring feature creation as there are many features in this data set already. Since exploratory data analysis has already been covered in the other notebook, we won't bother repeating it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.stats import skew\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up forward filling function\n",
    "\n",
    "def fill_nas(df):\n",
    "    \n",
    "    #Keeping tack of time\n",
    "    t0 = time.time()\n",
    "    \n",
    "    #Counting NaNs\n",
    "    na_count = df.isna().sum().sum()\n",
    "    \n",
    "    while na_count>0:\n",
    "        df = df.sample(frac=1)\n",
    "        df = df.fillna(method='ffill',limit=1)\n",
    "        na_count = df.isna().sum().sum()\n",
    "\n",
    "    filled_df = df.sort_index()\n",
    "    \n",
    "    #Calculating time taken\n",
    "    t1 = time.time()\n",
    "    print(t1-t0)\n",
    "    \n",
    "    #Return filled df\n",
    "    return(filled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Data/train.csv')\n",
    "test = pd.read_csv('Data/test.csv')\n",
    "\n",
    "#Stripping SalePrice from the training data and combining with the test data\n",
    "SalePrice = np.log(train['SalePrice'])\n",
    "train = train.drop('SalePrice',axis=1)\n",
    "X = pd.concat([train,test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing some data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MSSubClass is a categorical variable, so we convert it to a string \n",
    "X['MSSubClass'] = X['MSSubClass'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01822805404663086\n"
     ]
    }
   ],
   "source": [
    "##Dealing with numerics\n",
    "numerics = X.select_dtypes(exclude='object')\n",
    "\n",
    "#Filling nas\n",
    "numerics = fill_nas(numerics)\n",
    "\n",
    "#log transformation of skewed variables\n",
    "skews = numerics.apply(lambda x:skew(x.dropna()))\n",
    "skewed = skews>0.75\n",
    "skewed_data = numerics[skewed.index[skewed]]\n",
    "skewed_feats = skewed_data.columns\n",
    "numerics = numerics.drop(skewed_feats, axis=1)\n",
    "log_transformed = np.log1p(skewed_data)\n",
    "numerics = pd.concat([numerics,log_transformed],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 348) (1459, 348)\n",
      "(1460, 349) (1459, 80)\n"
     ]
    }
   ],
   "source": [
    "#Dealing with strings\n",
    "strings = X.select_dtypes(include='object')\n",
    "\n",
    "#Converting strings to dummies and joining with numerics\n",
    "dummies = pd.get_dummies(strings, dummy_na=True)\n",
    "X = pd.concat([numerics,dummies],axis=1)\n",
    "\n",
    "#Splitting into train and test data\n",
    "X_train = X.iloc[:train.shape[0],]\n",
    "X_test = X.iloc[train.shape[0]:,]\n",
    "train = pd.concat([SalePrice,X_train],axis=1)\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now that the initial data preprocessing has been done, we are now going to set up cross-validation and Bayesian optimisation procedures for each model. The reason why we use Bayesian Optimisation for hyperparameter tuning is because of the stochastic nature of our objective function. We are randomly sorting the data to better replicate the variability in the dgp when measuring the validation score. While a deterministic optimiser may work, it may not be the best solution if it does not account for the noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up optimisation for Ridge regression model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "def ridge_score(alpha):\n",
    "    train_data = train.sample(frac=1)\n",
    "    X=train_data.iloc[:,1:]\n",
    "    y=train_data['SalePrice']\n",
    "    \n",
    "    scores = cross_val_score(estimator=Ridge(alpha=alpha), X=X, y=y, scoring='neg_mean_squared_error', cv=5)\n",
    "    return(-np.average(np.sqrt(-scores)))\n",
    "\n",
    "bounds_ridge = {'alpha': (0,20)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the parameter bounds, I have chosen alpha to be between 0 and 20. Using a 0 value will be equivalent to estimation by OLS, any positive values will shrink the parameter estimates towards zero. I do not want to using an upper bound that is too high as it will waste computation power as in practice, optimal values for alpha are relatively small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   alpha   |\n",
      "-------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.1287  \u001b[0m | \u001b[0m 9.72    \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-0.1265  \u001b[0m | \u001b[95m 10.92   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.1317  \u001b[0m | \u001b[0m 14.69   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.1266  \u001b[0m | \u001b[0m 7.17    \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.132   \u001b[0m | \u001b[0m 1.477   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.1297  \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.1516  \u001b[0m | \u001b[0m 0.001091\u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.1265  \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.1265  \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.1288  \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.1283  \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.1331  \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.1272  \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.1315  \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.1315  \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.1297  \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-8.803e+1\u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.1283  \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.1292  \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.1299  \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.1426  \u001b[0m | \u001b[0m 0.001095\u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.1292  \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.1301  \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.1288  \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.1292  \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.131   \u001b[0m | \u001b[0m 1.477   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.1311  \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.1301  \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.1311  \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.1305  \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m-0.129   \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m-0.132   \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m-0.1285  \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m-0.1279  \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m-0.1301  \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m-0.1274  \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m-0.1302  \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m-0.134   \u001b[0m | \u001b[0m 1.477   \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m-0.1274  \u001b[0m | \u001b[0m 7.17    \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m-0.1298  \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m-0.1279  \u001b[0m | \u001b[0m 1.477   \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m-0.1305  \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m-0.1435  \u001b[0m | \u001b[0m 0.001098\u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m-0.1311  \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m-0.1337  \u001b[0m | \u001b[0m 1.477   \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m-0.127   \u001b[0m | \u001b[0m 10.92   \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m-0.1305  \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m-0.1291  \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m-0.1303  \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m-0.1293  \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m-0.1284  \u001b[0m | \u001b[0m 10.92   \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m-0.128   \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m-0.1309  \u001b[0m | \u001b[0m 1.477   \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m-0.1281  \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m-0.1289  \u001b[0m | \u001b[0m 10.92   \u001b[0m |\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "#Running Bayes Opt to tune ridge regression\n",
    "\n",
    "BO = BayesianOptimization(ridge_score, bounds_ridge)\n",
    "BO.maximize(n_iter=50,alpha=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal choice of alpha seems to be around 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up optimisation for Lasso model\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "def lasso_score(alpha):\n",
    "    train_data = train.sample(frac=1)\n",
    "    X=train_data.iloc[:,1:]\n",
    "    y=train_data['SalePrice']\n",
    "\n",
    "    scores = cross_val_score(estimator=Lasso(alpha=alpha, max_iter=10000), X=X, y=y, scoring='neg_mean_squared_error', cv=5)\n",
    "    return(-np.average(np.sqrt(-scores)))\n",
    "\n",
    "bounds_lasso = {'alpha': (0.00001,20)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm adjusting the bounds for the lasso as 0 values for regularisation cause convergence problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   alpha   |\n",
      "-------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.305   \u001b[0m | \u001b[0m 7.299   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.3066  \u001b[0m | \u001b[0m 9.549   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.3148  \u001b[0m | \u001b[0m 17.51   \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m-0.3044  \u001b[0m | \u001b[95m 5.857   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.316   \u001b[0m | \u001b[0m 19.1    \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m-0.1356  \u001b[0m | \u001b[95m 1.006e-0\u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.1363  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m-0.132   \u001b[0m | \u001b[95m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.132   \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.132   \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.132   \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.1363  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.1418  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.1418  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.1418  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.1418  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.1418  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.1418  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.1418  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.1418  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.1418  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.1418  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.1418  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.1418  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.1418  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.1418  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.1418  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.1418  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.1418  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.1418  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m-0.1418  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m-0.1418  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m-0.1394  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m-0.1394  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m-0.1352  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m-0.1352  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m-0.1352  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m-0.1396  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m-0.1396  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m-0.136   \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m-0.136   \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m-0.1338  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m-0.1338  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m-0.1338  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m-0.1338  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m-0.1338  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m-0.1397  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m-0.1366  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m-0.1373  \u001b[0m | \u001b[0m 1.001e-0\u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m-0.1366  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m-0.1405  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m-0.1405  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m-0.1365  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m-0.1365  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m-0.1397  \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "#Running Bayes Opt to tune Lasso regression\n",
    "\n",
    "BO = BayesianOptimization(lasso_score, bounds_lasso)\n",
    "BO.maximize(n_iter=50,alpha=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm quite suspicious about the behaviour of the Bayes optimiser in this case, it cannot seem to explore other values than the lower bound. While I could change the lower bound, it will cause convergence issues and will require an increased number of iterations. I can handpick a value for alpha that does noticeably better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.12857380432989013"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_score(0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point I'm not going to try delve into the workings of optimiser as I don't think it will be very fruitful. Instead I'm going to try using a different optimiser to see if we get better convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: -0.2677542767110079\n",
       " hess_inv: <1x1 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([6881.69102627])\n",
       "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
       "     nfev: 50\n",
       "      nit: 2\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.99999875])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "minimize(lasso_score, x0=1, bounds = ((0.00001,20),), tol=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also performs quite poorly. I think it gets thrown off by the randomness of the objective function. It does find a good optimum, but only if I put in an optimal starting point!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: -0.12544040196865947\n",
       " hess_inv: <1x1 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([-196060.25283075])\n",
       "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
       "     nfev: 32\n",
       "      nit: 2\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.00097682])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimize(lasso_score, x0=0.001, bounds = ((0.00001,20),), tol=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "With a good choice of alpha, the lasso marginally outpeforms the ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating optimizer for a Random Forests regressor\n",
    "from sklearn.ensemble import RandomForestRegressor as RF\n",
    "\n",
    "def RF_score(n_estimators,max_depth,min_samples_split,min_samples_leaf,max_features):\n",
    "    \n",
    "    #Contraining hyperparameters to be converted to integers (e.g. number of decision trees can't be continuous!)\n",
    "    n_estimators = int(n_estimators)\n",
    "    max_depth = int(max_depth)\n",
    "    min_samples_split = int(min_samples_split)\n",
    "    min_samples_leaf = int(min_samples_leaf)\n",
    "    max_features = int(max_features)\n",
    "    \n",
    "    assert type(n_estimators) == int\n",
    "    assert type(max_depth) == int\n",
    "    assert type(min_samples_split) == int\n",
    "    assert type(min_samples_leaf) == int\n",
    "    assert type(max_features) == int\n",
    "    \n",
    "    train_data = train.sample(frac=1)\n",
    "    X=train_data.iloc[:,1:]\n",
    "    y=train_data['SalePrice']\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        estimator=RF(\n",
    "                    n_estimators=n_estimators, \n",
    "                    max_depth=max_depth, \n",
    "                    min_samples_split=min_samples_split,\n",
    "                    min_samples_leaf = min_samples_leaf,\n",
    "                    max_features = max_features),\n",
    "    X=X, y=y, scoring='neg_mean_squared_error', cv=5)\n",
    "    return(-np.average(np.sqrt(-scores)))\n",
    "\n",
    "bounds_RF = {\n",
    "    'n_estimators': (1,3000),\n",
    "    'max_depth': (1,100),\n",
    "    'min_samples_split': (2,200),\n",
    "    'min_samples_leaf': (1,200),\n",
    "    'max_features': (1,290)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | max_fe... | min_sa... | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.2525  \u001b[0m | \u001b[0m 83.77   \u001b[0m | \u001b[0m 47.77   \u001b[0m | \u001b[0m 165.1   \u001b[0m | \u001b[0m 117.2   \u001b[0m | \u001b[0m 44.25   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.2654  \u001b[0m | \u001b[0m 63.19   \u001b[0m | \u001b[0m 22.49   \u001b[0m | \u001b[0m 145.3   \u001b[0m | \u001b[0m 133.5   \u001b[0m | \u001b[0m 2.303e+0\u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m-0.2111  \u001b[0m | \u001b[95m 65.32   \u001b[0m | \u001b[95m 236.2   \u001b[0m | \u001b[95m 107.6   \u001b[0m | \u001b[95m 143.9   \u001b[0m | \u001b[95m 946.7   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.2505  \u001b[0m | \u001b[0m 6.298   \u001b[0m | \u001b[0m 263.0   \u001b[0m | \u001b[0m 158.0   \u001b[0m | \u001b[0m 167.8   \u001b[0m | \u001b[0m 1.276e+0\u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.2573  \u001b[0m | \u001b[0m 6.909   \u001b[0m | \u001b[0m 273.4   \u001b[0m | \u001b[0m 197.2   \u001b[0m | \u001b[0m 141.0   \u001b[0m | \u001b[0m 1.167e+0\u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.2822  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 290.0   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 41.37   \u001b[0m | \u001b[0m 3e+03   \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m-0.1475  \u001b[0m | \u001b[95m 99.28   \u001b[0m | \u001b[95m 31.63   \u001b[0m | \u001b[95m 3.139   \u001b[0m | \u001b[95m 9.578   \u001b[0m | \u001b[95m 1.143e+0\u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.3804  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 1.114e+0\u001b[0m |\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m-0.1405  \u001b[0m | \u001b[95m 100.0   \u001b[0m | \u001b[95m 290.0   \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 2.0     \u001b[0m | \u001b[95m 1.918e+0\u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.2284  \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 290.0   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.3872  \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 3e+03   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.2583  \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 290.0   \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 2.569e+0\u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.3871  \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 1.573e+0\u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.141   \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 290.0   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 1.262e+0\u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.2726  \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 2.715e+0\u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.2742  \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 290.0   \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.1428  \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 290.0   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 2.48e+03\u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.3507  \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.3884  \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 548.5   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.2054  \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 290.0   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 2.147e+0\u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.2585  \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 290.0   \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 2.113e+0\u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.2048  \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 290.0   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 1.205e+0\u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.1814  \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 2.095e+0\u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.283   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 290.0   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 2.292e+0\u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.2593  \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 290.0   \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 1.529e+0\u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.2055  \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 290.0   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 3e+03   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.3004  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 290.0   \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[95m 28      \u001b[0m | \u001b[95m-0.1402  \u001b[0m | \u001b[95m 100.0   \u001b[0m | \u001b[95m 290.0   \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 2.0     \u001b[0m | \u001b[95m 513.6   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.2583  \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 290.0   \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 428.4   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.2574  \u001b[0m | \u001b[0m 93.44   \u001b[0m | \u001b[0m 289.8   \u001b[0m | \u001b[0m 196.0   \u001b[0m | \u001b[0m 8.438   \u001b[0m | \u001b[0m 910.4   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m-0.1409  \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 290.0   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 2.815e+0\u001b[0m |\n",
      "| \u001b[95m 32      \u001b[0m | \u001b[95m-0.14    \u001b[0m | \u001b[95m 100.0   \u001b[0m | \u001b[95m 138.6   \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 5.453   \u001b[0m | \u001b[95m 1.474e+0\u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m-0.1494  \u001b[0m | \u001b[0m 96.84   \u001b[0m | \u001b[0m 106.1   \u001b[0m | \u001b[0m 9.409   \u001b[0m | \u001b[0m 3.825   \u001b[0m | \u001b[0m 2.457e+0\u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m-0.197   \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 142.4   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 624.2   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m-0.143   \u001b[0m | \u001b[0m 97.8    \u001b[0m | \u001b[0m 140.5   \u001b[0m | \u001b[0m 4.029   \u001b[0m | \u001b[0m 7.622   \u001b[0m | \u001b[0m 294.0   \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m-0.1878  \u001b[0m | \u001b[0m 98.66   \u001b[0m | \u001b[0m 281.6   \u001b[0m | \u001b[0m 2.472   \u001b[0m | \u001b[0m 129.1   \u001b[0m | \u001b[0m 280.3   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m-0.258   \u001b[0m | \u001b[0m 91.34   \u001b[0m | \u001b[0m 286.2   \u001b[0m | \u001b[0m 199.1   \u001b[0m | \u001b[0m 6.016   \u001b[0m | \u001b[0m 2.997e+0\u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m-0.14    \u001b[0m | \u001b[0m 97.13   \u001b[0m | \u001b[0m 233.5   \u001b[0m | \u001b[0m 1.137   \u001b[0m | \u001b[0m 7.655   \u001b[0m | \u001b[0m 911.0   \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m-0.1671  \u001b[0m | \u001b[0m 99.92   \u001b[0m | \u001b[0m 131.6   \u001b[0m | \u001b[0m 29.78   \u001b[0m | \u001b[0m 44.94   \u001b[0m | \u001b[0m 1.182e+0\u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m-0.399   \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m-0.2028  \u001b[0m | \u001b[0m 95.08   \u001b[0m | \u001b[0m 277.7   \u001b[0m | \u001b[0m 5.086   \u001b[0m | \u001b[0m 198.8   \u001b[0m | \u001b[0m 1.661e+0\u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m-0.1569  \u001b[0m | \u001b[0m 6.457   \u001b[0m | \u001b[0m 228.0   \u001b[0m | \u001b[0m 14.58   \u001b[0m | \u001b[0m 3.458   \u001b[0m | \u001b[0m 317.9   \u001b[0m |\n",
      "| \u001b[95m 43      \u001b[0m | \u001b[95m-0.1386  \u001b[0m | \u001b[95m 99.84   \u001b[0m | \u001b[95m 81.03   \u001b[0m | \u001b[95m 1.853   \u001b[0m | \u001b[95m 3.489   \u001b[0m | \u001b[95m 1.736e+0\u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m-0.1546  \u001b[0m | \u001b[0m 99.46   \u001b[0m | \u001b[0m 255.3   \u001b[0m | \u001b[0m 14.54   \u001b[0m | \u001b[0m 13.02   \u001b[0m | \u001b[0m 1.705e+0\u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m-0.1759  \u001b[0m | \u001b[0m 98.54   \u001b[0m | \u001b[0m 279.6   \u001b[0m | \u001b[0m 12.34   \u001b[0m | \u001b[0m 95.06   \u001b[0m | \u001b[0m 2.66e+03\u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m-0.2728  \u001b[0m | \u001b[0m 1.802   \u001b[0m | \u001b[0m 139.1   \u001b[0m | \u001b[0m 143.7   \u001b[0m | \u001b[0m 196.5   \u001b[0m | \u001b[0m 217.9   \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m-0.1483  \u001b[0m | \u001b[0m 85.61   \u001b[0m | \u001b[0m 272.7   \u001b[0m | \u001b[0m 7.917   \u001b[0m | \u001b[0m 2.936   \u001b[0m | \u001b[0m 288.0   \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m-0.1416  \u001b[0m | \u001b[0m 97.48   \u001b[0m | \u001b[0m 108.2   \u001b[0m | \u001b[0m 2.205   \u001b[0m | \u001b[0m 4.692   \u001b[0m | \u001b[0m 682.5   \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m-0.3112  \u001b[0m | \u001b[0m 93.84   \u001b[0m | \u001b[0m 12.71   \u001b[0m | \u001b[0m 198.0   \u001b[0m | \u001b[0m 2.738   \u001b[0m | \u001b[0m 2.446e+0\u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m-0.2452  \u001b[0m | \u001b[0m 97.3    \u001b[0m | \u001b[0m 4.203   \u001b[0m | \u001b[0m 1.046   \u001b[0m | \u001b[0m 194.5   \u001b[0m | \u001b[0m 1.977e+0\u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m-0.1537  \u001b[0m | \u001b[0m 99.2    \u001b[0m | \u001b[0m 186.0   \u001b[0m | \u001b[0m 5.002   \u001b[0m | \u001b[0m 38.71   \u001b[0m | \u001b[0m 2.23e+03\u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m-0.1521  \u001b[0m | \u001b[0m 99.6    \u001b[0m | \u001b[0m 260.6   \u001b[0m | \u001b[0m 1.828   \u001b[0m | \u001b[0m 36.57   \u001b[0m | \u001b[0m 764.7   \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m-0.14    \u001b[0m | \u001b[0m 94.88   \u001b[0m | \u001b[0m 211.5   \u001b[0m | \u001b[0m 1.569   \u001b[0m | \u001b[0m 10.47   \u001b[0m | \u001b[0m 2.99e+03\u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m-0.1487  \u001b[0m | \u001b[0m 96.78   \u001b[0m | \u001b[0m 156.3   \u001b[0m | \u001b[0m 9.582   \u001b[0m | \u001b[0m 19.45   \u001b[0m | \u001b[0m 470.3   \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m-0.2577  \u001b[0m | \u001b[0m 94.13   \u001b[0m | \u001b[0m 285.3   \u001b[0m | \u001b[0m 184.4   \u001b[0m | \u001b[0m 193.8   \u001b[0m | \u001b[0m 1.302e+0\u001b[0m |\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "#Running Bayes Opt to tune Rando Forests regression\n",
    "\n",
    "BO = BayesianOptimization(RF_score, bounds_RF)\n",
    "BO.maximize(n_iter=50,alpha=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating optimiser for xgboost, note that doing it this way isn't entirely necessary\n",
    "#xgboost already contains the inbuilt functionality to do so, but I want to be consistent in my approach\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import xgboost as xgb\n",
    "\n",
    "def xgb_score(eta, max_depth, gamma, colsample, subsample, early_stop):\n",
    "    \n",
    "    #Contraining hyperparameters to be converted to integers (e.g. number of decision trees can't be continuous!)\n",
    "    max_depth = int(max_depth)\n",
    "    early_stop = int(early_stop)\n",
    "    \n",
    "    #assert type(n_estimators) == int\n",
    "    assert type(max_depth) == int\n",
    "    assert type(early_stop) == int\n",
    "    \n",
    "    train_data = train.sample(frac=1)\n",
    "    X=train_data.iloc[:,1:]\n",
    "    y=np.array(train_data['SalePrice'])\n",
    "    \n",
    "\n",
    "    xgb_model = xgb.XGBRegressor(learning_rate=0.1, \n",
    "                                 max_depth=max_depth, \n",
    "                                 min_split_loss=gamma, \n",
    "                                 colsample_bytree = colsample,\n",
    "                                 subsample = subsample,\n",
    "                                 early_stopping_rounds = early_stop,\n",
    "                                 objective=\"reg:squarederror\")\n",
    "    \n",
    "    scores = cross_val_score(estimator=xgb_model, X=X, y=y, scoring='neg_mean_squared_error', cv=5)\n",
    "    return(-np.average(np.sqrt(-scores)))\n",
    "\n",
    "bounds_xgb = {'eta': (0.01,0.5),\n",
    "              'max_depth':(3,40),\n",
    "              'gamma':(0,0.4), \n",
    "              'colsample':(0.3,1), \n",
    "              'subsample':(0.3,1),\n",
    "              'early_stop':(1,15)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsample | early_... |    eta    |   gamma   | max_depth | subsample |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.1421  \u001b[0m | \u001b[0m 0.9163  \u001b[0m | \u001b[0m 8.453   \u001b[0m | \u001b[0m 0.07675 \u001b[0m | \u001b[0m 0.3335  \u001b[0m | \u001b[0m 19.24   \u001b[0m | \u001b[0m 0.9383  \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-0.1381  \u001b[0m | \u001b[95m 0.4751  \u001b[0m | \u001b[95m 11.29   \u001b[0m | \u001b[95m 0.118   \u001b[0m | \u001b[95m 0.2687  \u001b[0m | \u001b[95m 11.04   \u001b[0m | \u001b[95m 0.7378  \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m-0.1326  \u001b[0m | \u001b[95m 0.7861  \u001b[0m | \u001b[95m 13.81   \u001b[0m | \u001b[95m 0.08371 \u001b[0m | \u001b[95m 0.07473 \u001b[0m | \u001b[95m 21.65   \u001b[0m | \u001b[95m 0.8461  \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m-0.1305  \u001b[0m | \u001b[95m 0.7299  \u001b[0m | \u001b[95m 9.31    \u001b[0m | \u001b[95m 0.4099  \u001b[0m | \u001b[95m 0.1261  \u001b[0m | \u001b[95m 27.06   \u001b[0m | \u001b[95m 0.3844  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.1388  \u001b[0m | \u001b[0m 0.3472  \u001b[0m | \u001b[0m 1.883   \u001b[0m | \u001b[0m 0.03803 \u001b[0m | \u001b[0m 0.2748  \u001b[0m | \u001b[0m 15.2    \u001b[0m | \u001b[0m 0.9554  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.1369  \u001b[0m | \u001b[0m 0.5111  \u001b[0m | \u001b[0m 1.219   \u001b[0m | \u001b[0m 0.2971  \u001b[0m | \u001b[0m 0.002935\u001b[0m | \u001b[0m 39.98   \u001b[0m | \u001b[0m 0.3715  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.1398  \u001b[0m | \u001b[0m 0.3249  \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 0.3365  \u001b[0m | \u001b[0m 0.3099  \u001b[0m | \u001b[0m 39.91   \u001b[0m | \u001b[0m 0.4689  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.1309  \u001b[0m | \u001b[0m 0.9567  \u001b[0m | \u001b[0m 1.13    \u001b[0m | \u001b[0m 0.2592  \u001b[0m | \u001b[0m 0.02828 \u001b[0m | \u001b[0m 3.003   \u001b[0m | \u001b[0m 0.7279  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.1337  \u001b[0m | \u001b[0m 0.6189  \u001b[0m | \u001b[0m 1.046   \u001b[0m | \u001b[0m 0.2366  \u001b[0m | \u001b[0m 0.08828 \u001b[0m | \u001b[0m 3.002   \u001b[0m | \u001b[0m 0.4639  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.1425  \u001b[0m | \u001b[0m 0.6641  \u001b[0m | \u001b[0m 14.76   \u001b[0m | \u001b[0m 0.4694  \u001b[0m | \u001b[0m 0.2594  \u001b[0m | \u001b[0m 3.012   \u001b[0m | \u001b[0m 0.3292  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.1381  \u001b[0m | \u001b[0m 0.5835  \u001b[0m | \u001b[0m 1.037   \u001b[0m | \u001b[0m 0.4114  \u001b[0m | \u001b[0m 0.1929  \u001b[0m | \u001b[0m 39.95   \u001b[0m | \u001b[0m 0.7457  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.1406  \u001b[0m | \u001b[0m 0.5551  \u001b[0m | \u001b[0m 1.106   \u001b[0m | \u001b[0m 0.3686  \u001b[0m | \u001b[0m 0.3612  \u001b[0m | \u001b[0m 40.0    \u001b[0m | \u001b[0m 0.4581  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.1353  \u001b[0m | \u001b[0m 0.3469  \u001b[0m | \u001b[0m 14.95   \u001b[0m | \u001b[0m 0.3582  \u001b[0m | \u001b[0m 0.2051  \u001b[0m | \u001b[0m 3.03    \u001b[0m | \u001b[0m 0.5816  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.1391  \u001b[0m | \u001b[0m 0.3998  \u001b[0m | \u001b[0m 14.9    \u001b[0m | \u001b[0m 0.4874  \u001b[0m | \u001b[0m 0.3455  \u001b[0m | \u001b[0m 3.01    \u001b[0m | \u001b[0m 0.5654  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.1328  \u001b[0m | \u001b[0m 0.7921  \u001b[0m | \u001b[0m 1.039   \u001b[0m | \u001b[0m 0.3033  \u001b[0m | \u001b[0m 0.03781 \u001b[0m | \u001b[0m 39.98   \u001b[0m | \u001b[0m 0.3526  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.132   \u001b[0m | \u001b[0m 0.9368  \u001b[0m | \u001b[0m 1.025   \u001b[0m | \u001b[0m 0.03736 \u001b[0m | \u001b[0m 0.04424 \u001b[0m | \u001b[0m 39.94   \u001b[0m | \u001b[0m 0.3343  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.1384  \u001b[0m | \u001b[0m 0.5048  \u001b[0m | \u001b[0m 1.028   \u001b[0m | \u001b[0m 0.17    \u001b[0m | \u001b[0m 0.2697  \u001b[0m | \u001b[0m 39.99   \u001b[0m | \u001b[0m 0.9216  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.1332  \u001b[0m | \u001b[0m 0.7636  \u001b[0m | \u001b[0m 14.85   \u001b[0m | \u001b[0m 0.2068  \u001b[0m | \u001b[0m 0.1042  \u001b[0m | \u001b[0m 3.006   \u001b[0m | \u001b[0m 0.9574  \u001b[0m |\n",
      "| \u001b[95m 19      \u001b[0m | \u001b[95m-0.129   \u001b[0m | \u001b[95m 0.5977  \u001b[0m | \u001b[95m 14.96   \u001b[0m | \u001b[95m 0.1622  \u001b[0m | \u001b[95m 0.000487\u001b[0m | \u001b[95m 3.041   \u001b[0m | \u001b[95m 0.6669  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.1326  \u001b[0m | \u001b[0m 0.5514  \u001b[0m | \u001b[0m 14.96   \u001b[0m | \u001b[0m 0.1227  \u001b[0m | \u001b[0m 0.04177 \u001b[0m | \u001b[0m 3.079   \u001b[0m | \u001b[0m 0.8157  \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.1333  \u001b[0m | \u001b[0m 0.4639  \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 0.0989  \u001b[0m | \u001b[0m 0.1601  \u001b[0m | \u001b[0m 3.019   \u001b[0m | \u001b[0m 0.3443  \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.1341  \u001b[0m | \u001b[0m 0.3115  \u001b[0m | \u001b[0m 1.117   \u001b[0m | \u001b[0m 0.248   \u001b[0m | \u001b[0m 0.2526  \u001b[0m | \u001b[0m 3.016   \u001b[0m | \u001b[0m 0.9844  \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.1297  \u001b[0m | \u001b[0m 0.4343  \u001b[0m | \u001b[0m 14.99   \u001b[0m | \u001b[0m 0.3718  \u001b[0m | \u001b[0m 0.1153  \u001b[0m | \u001b[0m 39.95   \u001b[0m | \u001b[0m 0.4056  \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.1383  \u001b[0m | \u001b[0m 0.5182  \u001b[0m | \u001b[0m 14.95   \u001b[0m | \u001b[0m 0.1694  \u001b[0m | \u001b[0m 0.2044  \u001b[0m | \u001b[0m 39.99   \u001b[0m | \u001b[0m 0.9092  \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.1351  \u001b[0m | \u001b[0m 0.9479  \u001b[0m | \u001b[0m 1.064   \u001b[0m | \u001b[0m 0.2458  \u001b[0m | \u001b[0m 0.228   \u001b[0m | \u001b[0m 3.006   \u001b[0m | \u001b[0m 0.7444  \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.1335  \u001b[0m | \u001b[0m 0.762   \u001b[0m | \u001b[0m 14.98   \u001b[0m | \u001b[0m 0.3499  \u001b[0m | \u001b[0m 0.005964\u001b[0m | \u001b[0m 40.0    \u001b[0m | \u001b[0m 0.6048  \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.1299  \u001b[0m | \u001b[0m 0.8491  \u001b[0m | \u001b[0m 1.022   \u001b[0m | \u001b[0m 0.3372  \u001b[0m | \u001b[0m 0.04612 \u001b[0m | \u001b[0m 3.056   \u001b[0m | \u001b[0m 0.9479  \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.1328  \u001b[0m | \u001b[0m 0.6795  \u001b[0m | \u001b[0m 1.071   \u001b[0m | \u001b[0m 0.1613  \u001b[0m | \u001b[0m 0.1146  \u001b[0m | \u001b[0m 3.03    \u001b[0m | \u001b[0m 0.8944  \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.135   \u001b[0m | \u001b[0m 0.5258  \u001b[0m | \u001b[0m 1.179   \u001b[0m | \u001b[0m 0.3735  \u001b[0m | \u001b[0m 0.261   \u001b[0m | \u001b[0m 3.015   \u001b[0m | \u001b[0m 0.7036  \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.1459  \u001b[0m | \u001b[0m 0.5472  \u001b[0m | \u001b[0m 14.91   \u001b[0m | \u001b[0m 0.3465  \u001b[0m | \u001b[0m 0.3992  \u001b[0m | \u001b[0m 39.96   \u001b[0m | \u001b[0m 0.484   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m-0.1313  \u001b[0m | \u001b[0m 0.3345  \u001b[0m | \u001b[0m 1.19    \u001b[0m | \u001b[0m 0.3903  \u001b[0m | \u001b[0m 0.03393 \u001b[0m | \u001b[0m 3.002   \u001b[0m | \u001b[0m 0.4929  \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m-0.1362  \u001b[0m | \u001b[0m 0.7747  \u001b[0m | \u001b[0m 1.047   \u001b[0m | \u001b[0m 0.03002 \u001b[0m | \u001b[0m 0.1948  \u001b[0m | \u001b[0m 3.027   \u001b[0m | \u001b[0m 0.4333  \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m-0.1375  \u001b[0m | \u001b[0m 0.4725  \u001b[0m | \u001b[0m 1.07    \u001b[0m | \u001b[0m 0.391   \u001b[0m | \u001b[0m 0.208   \u001b[0m | \u001b[0m 3.008   \u001b[0m | \u001b[0m 0.9154  \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m-0.1368  \u001b[0m | \u001b[0m 0.5598  \u001b[0m | \u001b[0m 14.95   \u001b[0m | \u001b[0m 0.1694  \u001b[0m | \u001b[0m 0.2798  \u001b[0m | \u001b[0m 3.02    \u001b[0m | \u001b[0m 0.4242  \u001b[0m |\n",
      "| \u001b[95m 35      \u001b[0m | \u001b[95m-0.1286  \u001b[0m | \u001b[95m 0.8823  \u001b[0m | \u001b[95m 1.112   \u001b[0m | \u001b[95m 0.1288  \u001b[0m | \u001b[95m 0.04007 \u001b[0m | \u001b[95m 39.98   \u001b[0m | \u001b[95m 0.5538  \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m-0.1403  \u001b[0m | \u001b[0m 0.7741  \u001b[0m | \u001b[0m 1.054   \u001b[0m | \u001b[0m 0.3346  \u001b[0m | \u001b[0m 0.2842  \u001b[0m | \u001b[0m 39.94   \u001b[0m | \u001b[0m 0.3109  \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m-0.1425  \u001b[0m | \u001b[0m 0.8918  \u001b[0m | \u001b[0m 1.086   \u001b[0m | \u001b[0m 0.169   \u001b[0m | \u001b[0m 0.3134  \u001b[0m | \u001b[0m 3.011   \u001b[0m | \u001b[0m 0.3111  \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m-0.1398  \u001b[0m | \u001b[0m 0.4318  \u001b[0m | \u001b[0m 14.74   \u001b[0m | \u001b[0m 0.3918  \u001b[0m | \u001b[0m 0.3949  \u001b[0m | \u001b[0m 40.0    \u001b[0m | \u001b[0m 0.4843  \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m-0.1335  \u001b[0m | \u001b[0m 0.4278  \u001b[0m | \u001b[0m 14.8    \u001b[0m | \u001b[0m 0.3127  \u001b[0m | \u001b[0m 0.1887  \u001b[0m | \u001b[0m 3.02    \u001b[0m | \u001b[0m 0.9504  \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m-0.1389  \u001b[0m | \u001b[0m 0.9118  \u001b[0m | \u001b[0m 14.98   \u001b[0m | \u001b[0m 0.3477  \u001b[0m | \u001b[0m 0.3183  \u001b[0m | \u001b[0m 3.033   \u001b[0m | \u001b[0m 0.4727  \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m-0.1414  \u001b[0m | \u001b[0m 0.6635  \u001b[0m | \u001b[0m 1.154   \u001b[0m | \u001b[0m 0.1065  \u001b[0m | \u001b[0m 0.2877  \u001b[0m | \u001b[0m 39.93   \u001b[0m | \u001b[0m 0.3357  \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m-0.1354  \u001b[0m | \u001b[0m 0.8645  \u001b[0m | \u001b[0m 1.001   \u001b[0m | \u001b[0m 0.1087  \u001b[0m | \u001b[0m 0.1388  \u001b[0m | \u001b[0m 3.01    \u001b[0m | \u001b[0m 0.9076  \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m-0.1333  \u001b[0m | \u001b[0m 0.3641  \u001b[0m | \u001b[0m 14.87   \u001b[0m | \u001b[0m 0.2673  \u001b[0m | \u001b[0m 0.0859  \u001b[0m | \u001b[0m 3.102   \u001b[0m | \u001b[0m 0.6656  \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m-0.1417  \u001b[0m | \u001b[0m 0.3968  \u001b[0m | \u001b[0m 14.93   \u001b[0m | \u001b[0m 0.3931  \u001b[0m | \u001b[0m 0.3663  \u001b[0m | \u001b[0m 3.004   \u001b[0m | \u001b[0m 0.6151  \u001b[0m |\n",
      "| \u001b[95m 45      \u001b[0m | \u001b[95m-0.1265  \u001b[0m | \u001b[95m 0.9766  \u001b[0m | \u001b[95m 1.01    \u001b[0m | \u001b[95m 0.09145 \u001b[0m | \u001b[95m 0.0302  \u001b[0m | \u001b[95m 39.97   \u001b[0m | \u001b[95m 0.9682  \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m-0.1315  \u001b[0m | \u001b[0m 0.7125  \u001b[0m | \u001b[0m 1.03    \u001b[0m | \u001b[0m 0.2269  \u001b[0m | \u001b[0m 0.003604\u001b[0m | \u001b[0m 39.99   \u001b[0m | \u001b[0m 0.3973  \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m-0.1352  \u001b[0m | \u001b[0m 0.6523  \u001b[0m | \u001b[0m 1.011   \u001b[0m | \u001b[0m 0.2979  \u001b[0m | \u001b[0m 0.1106  \u001b[0m | \u001b[0m 39.98   \u001b[0m | \u001b[0m 0.5149  \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m-0.1313  \u001b[0m | \u001b[0m 0.3491  \u001b[0m | \u001b[0m 1.049   \u001b[0m | \u001b[0m 0.4327  \u001b[0m | \u001b[0m 0.1537  \u001b[0m | \u001b[0m 39.98   \u001b[0m | \u001b[0m 0.9182  \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m-0.1347  \u001b[0m | \u001b[0m 0.5481  \u001b[0m | \u001b[0m 1.034   \u001b[0m | \u001b[0m 0.2438  \u001b[0m | \u001b[0m 0.104   \u001b[0m | \u001b[0m 39.98   \u001b[0m | \u001b[0m 0.3492  \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m-0.1406  \u001b[0m | \u001b[0m 0.9482  \u001b[0m | \u001b[0m 1.011   \u001b[0m | \u001b[0m 0.3564  \u001b[0m | \u001b[0m 0.3222  \u001b[0m | \u001b[0m 39.99   \u001b[0m | \u001b[0m 0.6083  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 51      \u001b[0m | \u001b[0m-0.1326  \u001b[0m | \u001b[0m 0.5703  \u001b[0m | \u001b[0m 1.037   \u001b[0m | \u001b[0m 0.4504  \u001b[0m | \u001b[0m 0.1016  \u001b[0m | \u001b[0m 3.023   \u001b[0m | \u001b[0m 0.9569  \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m-0.1291  \u001b[0m | \u001b[0m 0.504   \u001b[0m | \u001b[0m 14.95   \u001b[0m | \u001b[0m 0.3867  \u001b[0m | \u001b[0m 0.0374  \u001b[0m | \u001b[0m 3.018   \u001b[0m | \u001b[0m 0.7305  \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m-0.1404  \u001b[0m | \u001b[0m 0.8258  \u001b[0m | \u001b[0m 14.99   \u001b[0m | \u001b[0m 0.3848  \u001b[0m | \u001b[0m 0.3104  \u001b[0m | \u001b[0m 3.009   \u001b[0m | \u001b[0m 0.4784  \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m-0.1383  \u001b[0m | \u001b[0m 0.5643  \u001b[0m | \u001b[0m 1.075   \u001b[0m | \u001b[0m 0.2045  \u001b[0m | \u001b[0m 0.1931  \u001b[0m | \u001b[0m 39.98   \u001b[0m | \u001b[0m 0.7325  \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m-0.1428  \u001b[0m | \u001b[0m 0.5509  \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 0.176   \u001b[0m | \u001b[0m 0.3965  \u001b[0m | \u001b[0m 3.013   \u001b[0m | \u001b[0m 0.7466  \u001b[0m |\n",
      "=================================================================================================\n"
     ]
    }
   ],
   "source": [
    "#Running Bayes Opt to tune Random Forests regression\n",
    "\n",
    "BO = BayesianOptimization(xgb_score, bounds_xgb)\n",
    "BO.maximize(n_iter=50,alpha=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now that we've tuned the hyperparameters using Bayes opt and gotten a good feel of how the models perform using different parameter sets, it's pretty easy to see that xgboost performs the best. As a final evaluation, I'll put in some paramter values to evaluate our models concurrently and then pick from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.1269655787503537 -0.12987026651616576 -0.14191146053416806 -0.1309665650518888\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    lasso_score(0.001),\n",
    "    ridge_score(10),\n",
    "    RF_score(n_estimators=20, \n",
    "                    max_depth=100, \n",
    "                    min_samples_split=2,\n",
    "                    min_samples_leaf = 1,\n",
    "                    max_features = 130),\n",
    "    xgb_score(eta=0.1,\n",
    "              max_depth=40,\n",
    "              gamma=0.05,\n",
    "              colsample=0.9,\n",
    "              subsample=0.7,\n",
    "              early_stop=10)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noted, xgboost clearly outperforms all other models. So we'll use that configuration to make our test predictions and submit on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    }
   ],
   "source": [
    "model_xgb = xgb.XGBRegressor(learning_rate=0.1, max_depth=10, min_split_loss=0, objective=\"reg:squarederror\")\n",
    "model_xgb.fit(X_train,SalePrice)\n",
    "xgb_preds = np.expm1(model_xgb.predict(X_test))\n",
    "\n",
    "\n",
    "#Submission csv\n",
    "submission = pd.read_csv('Data/sample_submission.csv')\n",
    "submission['SalePrice'] = xgb_preds\n",
    "submission.to_csv('Data/submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well! Turns out we did rather poorly despite all the work we put in, we got a public score of 0.14504 placing us in the bottom 50% :(."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lasso = Lasso(alpha=0.001)\n",
    "model_lasso.fit(X_train,SalePrice)\n",
    "lasso_preds = np.expm1(model_lasso.predict(X_test))\n",
    "\n",
    "#Submission csv\n",
    "submission = pd.read_csv('Data/sample_submission.csv')\n",
    "submission['SalePrice'] = lasso_preds\n",
    "submission.to_csv('Data/submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
